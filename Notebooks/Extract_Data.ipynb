{"cells":[{"cell_type":"markdown","source":["# Introduction to Preliminary Global Extraction, Transformation, and Loading (ETL) Process\n","In this notebook, we embark on the initial stages of the Extraction, Transformation, and Loading (ETL) process by retrieving data from a client-provided source. This extracted data will form the foundation for subsequent analysis and processing, ultimately guiding us to deliver the final product in alignment with the client's requirements. To streamline this process, we utilize a suite of specialized libraries that enable us to extract, transform, and organize the data efficiently.\n","\n","Our approach prioritizes clarity and simplicity in the implementation of code. We achieve this by minimizing the number of action cells and focusing on concise, well-documented functions. Where necessary, we provide detailed comments to facilitate understanding and collaboration throughout the ETL process.\n","\n","The structure of this notebook is modular, taking inspiration from the Model-View-Controller (MVC) design pattern. The sections are organized as follows:\n","\n","1. **Data Extraction Function**: This section defines the function responsible for extracting data from the client's drive and transferring it to the lakehouse.\n","\n","2. **Transform Functions**: Here, we define the function responsible for transform data in .parquet files for better work.\n","\n","3. **Load data**: This part we define the function responsible for load data in parquet format to the lakehouse.\n","\n","We refer to this systematic approach as the Library-Action-View (LAV) paradigm, reflecting our commitment to efficiency and organization in executing the ETL process."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d2ad33a4-9601-4a4b-a578-42a2c347ae59"},{"cell_type":"code","source":["pip install gdown "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"ada0f479-457e-4a1b-ba84-2ed58930e116","normalized_state":"finished","queued_time":"2024-09-03T01:07:50.220976Z","session_start_time":"2024-09-03T01:07:50.3083251Z","execution_start_time":"2024-09-03T01:07:59.0750433Z","execution_finish_time":"2024-09-03T01:08:07.8400917Z","parent_msg_id":"17e1aabc-78e3-42a2-9c14-bd6733371b35"},"text/plain":"StatementMeta(, ada0f479-457e-4a1b-ba84-2ed58930e116, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\nRequirement already satisfied: beautifulsoup4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from gdown) (3.11.0)\nRequirement already satisfied: requests[socks] in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: tqdm in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: soupsieve>1.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.17)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.7.22)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\nNote: you may need to restart the kernel to use updated packages.\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"76600a6d-d20c-45c4-8a8e-5ea2691d79b1"},{"cell_type":"code","source":["pip install pyarrow"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"ada0f479-457e-4a1b-ba84-2ed58930e116","normalized_state":"finished","queued_time":"2024-09-03T01:07:50.2264642Z","session_start_time":null,"execution_start_time":"2024-09-03T01:08:08.4710123Z","execution_finish_time":"2024-09-03T01:08:11.1392976Z","parent_msg_id":"5c7c80f1-b8dc-4377-8cb9-e4c940400a91"},"text/plain":"StatementMeta(, ada0f479-457e-4a1b-ba84-2ed58930e116, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyarrow in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (12.0.1)\nRequirement already satisfied: numpy>=1.16.6 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from pyarrow) (1.24.3)\nNote: you may need to restart the kernel to use updated packages.\n"]}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e5a8338f-b71d-4fe3-88f4-4abcc493cec7"},{"cell_type":"code","source":["import io\n","import os\n","import sys\n","import pandas as pd\n","import ast\n","import json\n","import numpy as np\n","import pyarrow as pa\n","import pyarrow.parquet as pq\n","#import builtin.utils as ut\n","import gdown"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"ada0f479-457e-4a1b-ba84-2ed58930e116","normalized_state":"finished","queued_time":"2024-09-03T01:07:50.227203Z","session_start_time":null,"execution_start_time":"2024-09-03T01:08:11.8462496Z","execution_finish_time":"2024-09-03T01:08:13.7127802Z","parent_msg_id":"ca518b3e-2592-4b7e-9506-021da49c5f5b"},"text/plain":"StatementMeta(, ada0f479-457e-4a1b-ba84-2ed58930e116, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c1dd1af5-f683-49af-944d-37591f555e90"},{"cell_type":"code","source":["def download_from_drive_folder(drive_folder_id, main_folder_path):\n","    # URL folder to download\n","    url = f\"https://drive.google.com/drive/folders/1hVEIP_DpRx-l-vRYlJiT6AGe7oZb1Plg?usp=sharing\"\n","    \n","    # Download folder content\n","    gdown.download_folder(url, output=main_folder_path, quiet=False, use_cookies=False)\n","\n","# Paameters\n","drive_id = '1ribEbkDnfG4IFtGcbQM0f8t1Mc846Agl'  # ID de tu carpeta en Drive\n","main_folder_path = '/lakehouse/default/Files/Original'  # Ruta de la carpeta destino\n","\n","# Call funtion \"download_from_drive_folder\"\n","download_from_drive_folder(drive_id, main_folder_path)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"ada0f479-457e-4a1b-ba84-2ed58930e116","normalized_state":"finished","queued_time":"2024-09-03T01:07:50.2277935Z","session_start_time":null,"execution_start_time":"2024-09-03T01:08:14.346802Z","execution_finish_time":"2024-09-03T01:08:51.5150067Z","parent_msg_id":"c6f826dd-5876-4a96-8fd9-1d4e7e5fac89"},"text/plain":"StatementMeta(, ada0f479-457e-4a1b-ba84-2ed58930e116, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Retrieving folder contents\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=1sAI6dJ92gbKGIrGIfg1kqexcOPwfaoAL\nTo: /lakehouse/default/Files/Original/Console_sales.xlsx\n100%|██████████| 12.7k/12.7k [00:00<00:00, 30.2MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1j2U0umBKidNL9AT8MnGLNpq3IqeujGk_\nTo: /lakehouse/default/Files/Original/Indicadores_del_desarrollo_humano_mundial Banco Mundial.xlsx\n100%|██████████| 85.3k/85.3k [00:00<00:00, 4.90MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1LSfAB64VsWp2s0vYYD3ma7EP7pEizF5n\nTo: /lakehouse/default/Files/Original/Juegos en steam.csv\n100%|██████████| 5.82M/5.82M [00:00<00:00, 66.1MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1AY79WPqiUYTjkYhvJ2NPOUyvjZ7DtZSC\nTo: /lakehouse/default/Files/Original/steam_games.json\n100%|██████████| 38.3M/38.3M [00:00<00:00, 75.2MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1WKbJv0mkgX-OeNHN5mJ-h4qC9q1wXrrR\nTo: /lakehouse/default/Files/Original/user_reviews.json\n100%|██████████| 26.3M/26.3M [00:00<00:00, 137MB/s] \nDownloading...\nFrom (original): https://drive.google.com/uc?id=1WHmXVApFOct2DkQ37PUEGpsxJe37RiIb\nFrom (redirected): https://drive.google.com/uc?id=1WHmXVApFOct2DkQ37PUEGpsxJe37RiIb&confirm=t&uuid=487ad48e-cd33-4808-a3f1-44f4a2239505\nTo: /lakehouse/default/Files/Original/users_items.json\n100%|██████████| 553M/553M [00:04<00:00, 119MB/s]  \nDownloading...\nFrom: https://drive.google.com/uc?id=1krfoHcqRd0qGv9t4L7MelHStQ6DdIMCk\nTo: /lakehouse/default/Files/Original/Video Games Sales.csv\n100%|██████████| 1.93M/1.93M [00:00<00:00, 24.8MB/s]\nDownload completed\n"]},{"output_type":"stream","name":"stdout","text":["Processing file 1sAI6dJ92gbKGIrGIfg1kqexcOPwfaoAL Console_sales.xlsx\nProcessing file 1j2U0umBKidNL9AT8MnGLNpq3IqeujGk_ Indicadores_del_desarrollo_humano_mundial Banco Mundial.xlsx\nProcessing file 1LSfAB64VsWp2s0vYYD3ma7EP7pEizF5n Juegos en steam.csv\nProcessing file 1AY79WPqiUYTjkYhvJ2NPOUyvjZ7DtZSC steam_games.json\nProcessing file 1WKbJv0mkgX-OeNHN5mJ-h4qC9q1wXrrR user_reviews.json\nProcessing file 1WHmXVApFOct2DkQ37PUEGpsxJe37RiIb users_items.json\nProcessing file 1krfoHcqRd0qGv9t4L7MelHStQ6DdIMCk Video Games Sales.csv\n"]}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"01469df2-ab4f-4548-999d-fef9c27f5091"},{"cell_type":"code","source":["def load_files_to_dataframe(main_folder_path):\n","    '''\n","    Function to read JSON, CSV, and XLSX files from a directory, process them,\n","    and return a dictionary of Pandas DataFrames.\n","\n","    Parameters:\n","    - main_folder_path (str): The path to the main folder containing subfolders with files.\n","\n","    Returns:\n","    - dicc (dict): A dictionary where keys are folder or file names and values are Pandas DataFrames.\n","    '''\n","    dicc = {}\n","\n","    for sub_folder in os.listdir(main_folder_path):\n","        sub_folder_path = os.path.join(main_folder_path, sub_folder)\n","\n","        # Process files in subfolders\n","        if os.path.isdir(sub_folder_path):\n","            folder_name = sub_folder\n","            dataframe_list = []\n","\n","            for file in os.listdir(sub_folder_path):\n","                file_path = os.path.join(sub_folder_path, file)\n","                dataframe_aux = read_file(file_path, file)\n","                if dataframe_aux is not None:\n","                    dataframe_list.append(dataframe_aux)\n","\n","            if dataframe_list:\n","                dataframe_object = pd.concat(dataframe_list, axis=0, ignore_index=True)\n","                dicc[folder_name] = dataframe_object\n","                print(f'Data from {folder_name} successfully loaded.')\n","\n","        # Process files in main folder\n","        elif sub_folder.endswith(('.json', '.csv', '.xlsx')):\n","            file_path = sub_folder_path\n","            file_name = sub_folder.split('.')[0]\n","\n","            dataframe_aux = read_file(file_path, sub_folder)\n","            if dataframe_aux is not None:\n","                dicc[file_name] = dataframe_aux\n","                print(f'File {file_name} successfully loaded.')\n","\n","    return dicc\n","\n","\n","def read_file(file_path, file_name):\n","    '''\n","    Helper function to read a file based on its extension and return a DataFrame.\n","    Tries different strategies for JSON files, reading them fully, line by line with ast.literal_eval,\n","    or line by line normalizing.\n","\n","    Parameters:\n","    - file_path (str): The path to the file.\n","    - file_name (str): The name of the file.\n","\n","    Returns:\n","    - df (pd.DataFrame): A Pandas DataFrame containing the data from the file or None if the file is empty or unsupported.\n","    '''\n","    if file_name.endswith('.json'):\n","        try:\n","            if os.path.getsize(file_path) > 0:\n","                return read_generic_json(file_path)\n","            else:\n","                print(f'File {file_name} is empty, skipping.')\n","                return None\n","        except ValueError as e:\n","            print(f'Error reading {file_name}: {e}')\n","            return None\n","    elif file_name.endswith('.csv'):\n","        return pd.read_csv(file_path)\n","    elif file_name.endswith('.xlsx'):\n","        return pd.read_excel(file_path)\n","    else:\n","        print(f'Unsupported file format: {file_name}')\n","        return None\n","\n","\n","def read_generic_json(file_path):\n","    '''\n","    Function to read JSON files and handle different formats:\n","    1. Full JSON reading.\n","    2. Line by line reading using ast.literal_eval.\n","    3. Line by line normalizing JSON objects.\n","\n","    Parameters:\n","    - file_path (str): The path to the JSON file.\n","\n","    Returns:\n","    - df (pd.DataFrame): A Pandas DataFrame containing the data from the JSON file.\n","    '''\n","    # Try 1: Read as JSON \n","    try:\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            data = json.load(f)\n","        return pd.DataFrame(data)\n","    \n","    except json.JSONDecodeError:\n","        print(f'Failed to load full JSON from {file_path}. Trying line-by-line methods.')\n","\n","    # Try 2: Read line by line using ast.literal_eval\n","    rows = []\n","    try:\n","        with open(file_path, encoding='utf-8') as f:\n","            for line in f.readlines():\n","                rows.append(ast.literal_eval(line))\n","        return pd.DataFrame(rows)\n","    \n","    except (ValueError, SyntaxError):\n","        print(f'Failed to parse JSON with ast.literal_eval for {file_path}. Trying normalization.')\n","\n","    # Try  3: Read line by line normalizing JSON\n","    try:\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            content = f.read()\n","        json_obj = [json.loads(line) for line in content.split('\\n') if line.strip()]\n","        return pd.json_normalize(json_obj)\n","    \n","    except Exception as e:\n","        print(f'All parsing methods failed for {file_path}. Error: {e}')\n","        return None"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"ada0f479-457e-4a1b-ba84-2ed58930e116","normalized_state":"finished","queued_time":"2024-09-03T01:07:50.2283976Z","session_start_time":null,"execution_start_time":"2024-09-03T01:08:51.9372748Z","execution_finish_time":"2024-09-03T01:08:52.1916818Z","parent_msg_id":"09cb8951-ac46-45fb-9705-43cc7122b317"},"text/plain":"StatementMeta(, ada0f479-457e-4a1b-ba84-2ed58930e116, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"161b7854-0d71-4ede-8d2d-8b01f0dc7e4b"},{"cell_type":"code","source":["def convert_column_to_string(dataframe, col):\n","    '''\n","    Converts a specific column in the dataframe to string (object dtype).\n","    \n","    Parameters:\n","    - dataframe (pd.DataFrame): The DataFrame containing the column.\n","    - col (str): The column to convert to string.\n","    \n","    Returns:\n","    - pd.Series: The column converted to string.\n","    '''\n","    dataframe[col] = dataframe[col].astype(str)\n","    return dataframe[col]\n","\n","def try_save_parquet(dataframe_aux, file_path):\n","    '''\n","    Tries to save the DataFrame as a Parquet file. If it fails, only converts problematic columns to string type.\n","    \n","    Parameters:\n","    - dataframe_aux (pd.DataFrame): The DataFrame to be saved.\n","    - file_path (str): The file path where the Parquet file will be saved.\n","    \n","    Returns:\n","    - None\n","    '''\n","    try:\n","        # Try to convert full  DataFrame to Parquet\n","        table = pa.Table.from_pandas(dataframe_aux)\n","        pq.write_table(table, file_path)\n","        print(f'Dataframe saved successfully at {file_path}')\n","    except Exception as e:\n","        print(f\"Error saving DataFrame at {file_path}: {e}\")\n","        print(\"Converting problematic columns to string and retrying...\")\n","        \n","        # Ir it fails, identify problematic columns\n","        problematic_columns = []\n","        for col in dataframe_aux.columns:\n","            try:\n","                # Try to convert column by column to parquet\n","                pa.array(dataframe_aux[col])\n","            except Exception:\n","                # when a column fails, mark as problematic column\n","                problematic_columns.append(col)\n","        \n","        # Converto the problematic columns to string\n","        for col in problematic_columns:\n","            dataframe_aux[col] = convert_column_to_string(dataframe_aux, col)\n","            print(f\"Column '{col}' converted to string.\")\n","\n","        # Try to save the dataframe again\n","        try:\n","            table = pa.Table.from_pandas(dataframe_aux)\n","            pq.write_table(table, file_path)\n","            print(f'Dataframe saved successfully after converting problematic columns to string at {file_path}')\n","        except Exception as final_error:\n","            print(f\"Final error saving DataFrame at {file_path}: {final_error}\")\n","\n","def dataframe_to_parquet(dicc, subfolder_name):\n","    '''\n","    Function to save Pandas DataFrames as Parquet files. If the conversion fails, it will convert problematic\n","    columns to string and retry saving.\n","    \n","    Parameters:\n","    - dicc (dict): A dictionary where keys are folder names and values are Pandas DataFrames.\n","    - subfolder_name (str): The desired subfolder name to be used in the file path.\n","    \n","    Returns:\n","    - None\n","    '''\n","    for key, dataframe_aux in dicc.items():\n","        # File path\n","        file_path = f'/lakehouse/default/Files/{subfolder_name}/{key}.parquet'\n","        \n","        # Save dataframee\n","        try_save_parquet(dataframe_aux, file_path)\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"ada0f479-457e-4a1b-ba84-2ed58930e116","normalized_state":"finished","queued_time":"2024-09-03T01:07:50.2290264Z","session_start_time":null,"execution_start_time":"2024-09-03T01:08:52.6059426Z","execution_finish_time":"2024-09-03T01:08:52.8541723Z","parent_msg_id":"e1fd275f-8866-4174-b4c4-acf5b718939a"},"text/plain":"StatementMeta(, ada0f479-457e-4a1b-ba84-2ed58930e116, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"02b8b05b-37ce-46d0-a6e0-0cccb38c9d12"},{"cell_type":"code","source":["# Load files in dataframes\n","main_folder_path = '/lakehouse/default/Files/Original' \n","dicc = load_files_to_dataframe(main_folder_path)\n","\n","# Save dataframes as parquet files\n","subfolder_name = 'Data_Parquet'\n","dataframe_to_parquet(dicc, subfolder_name)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"ada0f479-457e-4a1b-ba84-2ed58930e116","normalized_state":"finished","queued_time":"2024-09-03T01:07:50.2296565Z","session_start_time":null,"execution_start_time":"2024-09-03T01:08:53.2664185Z","execution_finish_time":"2024-09-03T01:10:46.1184487Z","parent_msg_id":"60e7c70f-c295-43bd-a72e-03997b3d27ae"},"text/plain":"StatementMeta(, ada0f479-457e-4a1b-ba84-2ed58930e116, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Failed to load full JSON from /lakehouse/default/Files/Original/steam_games.json. Trying line-by-line methods.\nFailed to parse JSON with ast.literal_eval for /lakehouse/default/Files/Original/steam_games.json. Trying normalization.\nFile steam_games successfully loaded.\nFile Indicadores_del_desarrollo_humano_mundial Banco Mundial successfully loaded.\nFailed to load full JSON from /lakehouse/default/Files/Original/user_reviews.json. Trying line-by-line methods.\nFile user_reviews successfully loaded.\nFailed to load full JSON from /lakehouse/default/Files/Original/users_items.json. Trying line-by-line methods.\nFile users_items successfully loaded.\nFile Juegos en steam successfully loaded.\nFile Console_sales successfully loaded.\nFile Video Games Sales successfully loaded.\nError saving DataFrame at /lakehouse/default/Files/Data_Parquet/steam_games.parquet: (\"Could not convert 'Free To Play' with type str: tried to convert to double\", 'Conversion failed for column price with type object')\nConverting problematic columns to string and retrying...\nColumn 'price' converted to string.\nDataframe saved successfully after converting problematic columns to string at /lakehouse/default/Files/Data_Parquet/steam_games.parquet\nError saving DataFrame at /lakehouse/default/Files/Data_Parquet/Indicadores_del_desarrollo_humano_mundial Banco Mundial.parquet: (\"Could not convert '..' with type str: tried to convert to double\", 'Conversion failed for column 2000 [YR2000] with type object')\nConverting problematic columns to string and retrying...\nColumn '2000 [YR2000]' converted to string.\nColumn '2001 [YR2001]' converted to string.\nColumn '2002 [YR2002]' converted to string.\nColumn '2003 [YR2003]' converted to string.\nColumn '2004 [YR2004]' converted to string.\nColumn '2005 [YR2005]' converted to string.\nColumn '2006 [YR2006]' converted to string.\nColumn '2007 [YR2007]' converted to string.\nColumn '2008 [YR2008]' converted to string.\nColumn '2009 [YR2009]' converted to string.\nColumn '2010 [YR2010]' converted to string.\nColumn '2011 [YR2011]' converted to string.\nColumn '2012 [YR2012]' converted to string.\nColumn '2013 [YR2013]' converted to string.\nColumn '2014 [YR2014]' converted to string.\nColumn '2015 [YR2015]' converted to string.\nColumn '2016 [YR2016]' converted to string.\nColumn '2017 [YR2017]' converted to string.\nColumn '2018 [YR2018]' converted to string.\nColumn '2019 [YR2019]' converted to string.\nDataframe saved successfully after converting problematic columns to string at /lakehouse/default/Files/Data_Parquet/Indicadores_del_desarrollo_humano_mundial Banco Mundial.parquet\nDataframe saved successfully at /lakehouse/default/Files/Data_Parquet/user_reviews.parquet\nDataframe saved successfully at /lakehouse/default/Files/Data_Parquet/users_items.parquet\nDataframe saved successfully at /lakehouse/default/Files/Data_Parquet/Juegos en steam.parquet\nDataframe saved successfully at /lakehouse/default/Files/Data_Parquet/Console_sales.parquet\nDataframe saved successfully at /lakehouse/default/Files/Data_Parquet/Video Games Sales.parquet\n"]}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"5e891648-8087-472c-854d-51fa4b6d0e36\",\"activityId\":\"ada0f479-457e-4a1b-ba84-2ed58930e116\",\"applicationId\":\"application_1725325503952_0001\",\"jobGroupId\":\"9\",\"advices\":{\"error\":1}}"}},"id":"b0b0d4c9-0d07-475d-aa4a-854bf2d1e982"},{"cell_type":"code","source":["def data_summ(df, title=None):\n","    '''\n","    Function to provide detailed information about the dtype, null values,\n","    and outliers for each column in a DataFrame.\n","\n","    Parameters:\n","    - df (pd.DataFrame): The DataFrame for which information is to be generated.\n","    - title (str, optional): Title to be used in the summary. If None, the title will be omitted.\n","\n","    Returns:\n","    - df_info (pd.DataFrame): A DataFrame containing information about each column,\n","                              including data type, non-missing quantity, percentage of\n","                              missing values, missing quantity, and information about outliers.\n","    '''\n","    info_dict = {\"Column\": [], \"Data_type\": [], \"No_miss_Qty\": [], \"%Missing\": [], \"Missing_Qty\": []}\n","\n","    for column in df.columns:\n","        info_dict[\"Column\"].append(column)\n","        info_dict[\"Data_type\"].append(df[column].apply(type).unique())\n","        info_dict[\"No_miss_Qty\"].append(df[column].count())\n","        info_dict[\"%Missing\"].append(round(df[column].isnull().sum() * 100 / len(df), 2))\n","        info_dict['Missing_Qty'].append(df[column].isnull().sum())\n","\n","  \n","    df_info = pd.DataFrame(info_dict)\n","\n","    if title:\n","        print(f\"{title} Summary\")\n","        print(\"\\nTotal rows: \", len(df))\n","        print(\"\\nTotal full null rows: \", df.isna().all(axis=1).sum())\n","\n","    print(df_info.to_string(index=False))\n","    print(\"=====================================\")\n","\n","    return df_info\n","\n","def data_summ_on_parquet(folder_path):\n","    '''\n","    Function to apply data_summ function to each Parquet file in a folder.\n","\n","    Parameters:\n","    - folder_path (str): The path to the folder containing Parquet files.\n","\n","    Returns:\n","    - summaries (list): A list of DataFrames containing the summary information for each Parquet file.\n","    '''\n","    summaries = []\n","\n","    # Loop through each file in the folder\n","    for file_name in os.listdir(folder_path):\n","        file_path = os.path.join(folder_path, file_name)\n","\n","        # Check if the file is a Parquet file\n","        if file_name.endswith('.parquet'):\n","            # Read the Parquet file into a DataFrame\n","            df = pq.read_table(file_path).to_pandas()\n","\n","            # Get the title for the DataFrame based on the file name\n","            title = file_name.replace('.parquet', '')\n","\n","            # Apply data_summ function to the DataFrame\n","            summary = data_summ(df, title=title)\n","\n","            # Append the summary DataFrame to the list\n","            summaries.append(summary)\n","\n","    return summaries"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"ada0f479-457e-4a1b-ba84-2ed58930e116","normalized_state":"finished","queued_time":"2024-09-03T01:07:50.230323Z","session_start_time":null,"execution_start_time":"2024-09-03T01:10:46.5984509Z","execution_finish_time":"2024-09-03T01:10:46.851391Z","parent_msg_id":"01b87022-2547-43c7-a9d8-770d46520d00"},"text/plain":"StatementMeta(, ada0f479-457e-4a1b-ba84-2ed58930e116, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"365748a3-f0e9-4450-bf71-333e205e3782"},{"cell_type":"code","source":["folder_path = '/lakehouse/default/Files/Data_Parquet' \n","data_summ_on_parquet(folder_path)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"ada0f479-457e-4a1b-ba84-2ed58930e116","normalized_state":"finished","queued_time":"2024-09-03T01:07:50.2309757Z","session_start_time":null,"execution_start_time":"2024-09-03T01:10:47.2881754Z","execution_finish_time":"2024-09-03T01:10:53.7303499Z","parent_msg_id":"a51809a5-4ae7-4fbf-a545-9e9d83e5017e"},"text/plain":"StatementMeta(, ada0f479-457e-4a1b-ba84-2ed58930e116, 11, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Juegos en steam Summary\n\nTotal rows:  27075\n\nTotal full null rows:  0\n          Column                           Data_type  No_miss_Qty  %Missing  Missing_Qty\n           appid                     [<class 'int'>]        27075      0.00            0\n            name                     [<class 'str'>]        27075      0.00            0\n    release_date                     [<class 'str'>]        27075      0.00            0\n         english                     [<class 'int'>]        27075      0.00            0\n       developer [<class 'str'>, <class 'NoneType'>]        27074      0.00            1\n       publisher [<class 'str'>, <class 'NoneType'>]        27061      0.05           14\n       platforms                     [<class 'str'>]        27075      0.00            0\n    required_age                     [<class 'int'>]        27075      0.00            0\n      categories                     [<class 'str'>]        27075      0.00            0\n          genres                     [<class 'str'>]        27075      0.00            0\n   steamspy_tags                     [<class 'str'>]        27075      0.00            0\n    achievements                     [<class 'int'>]        27075      0.00            0\npositive_ratings                     [<class 'int'>]        27075      0.00            0\nnegative_ratings                     [<class 'int'>]        27075      0.00            0\naverage_playtime                     [<class 'int'>]        27075      0.00            0\n median_playtime                     [<class 'int'>]        27075      0.00            0\n          owners                     [<class 'str'>]        27075      0.00            0\n           price                   [<class 'float'>]        27075      0.00            0\n=====================================\nIndicadores_del_desarrollo_humano_mundial Banco Mundial Summary\n\nTotal rows:  237\n\nTotal full null rows:  0\n       Column                           Data_type  No_miss_Qty  %Missing  Missing_Qty\n  Series Name [<class 'str'>, <class 'NoneType'>]          234      1.27            3\n  Series Code [<class 'str'>, <class 'NoneType'>]          232      2.11            5\n Country Name [<class 'str'>, <class 'NoneType'>]          232      2.11            5\n Country Code [<class 'str'>, <class 'NoneType'>]          232      2.11            5\n2000 [YR2000]                     [<class 'str'>]          237      0.00            0\n2001 [YR2001]                     [<class 'str'>]          237      0.00            0\n2002 [YR2002]                     [<class 'str'>]          237      0.00            0\n2003 [YR2003]                     [<class 'str'>]          237      0.00            0\n2004 [YR2004]                     [<class 'str'>]          237      0.00            0\n2005 [YR2005]                     [<class 'str'>]          237      0.00            0\n2006 [YR2006]                     [<class 'str'>]          237      0.00            0\n2007 [YR2007]                     [<class 'str'>]          237      0.00            0\n2008 [YR2008]                     [<class 'str'>]          237      0.00            0\n2009 [YR2009]                     [<class 'str'>]          237      0.00            0\n2010 [YR2010]                     [<class 'str'>]          237      0.00            0\n2011 [YR2011]                     [<class 'str'>]          237      0.00            0\n2012 [YR2012]                     [<class 'str'>]          237      0.00            0\n2013 [YR2013]                     [<class 'str'>]          237      0.00            0\n2014 [YR2014]                     [<class 'str'>]          237      0.00            0\n2015 [YR2015]                     [<class 'str'>]          237      0.00            0\n2016 [YR2016]                     [<class 'str'>]          237      0.00            0\n2017 [YR2017]                     [<class 'str'>]          237      0.00            0\n2018 [YR2018]                     [<class 'str'>]          237      0.00            0\n2019 [YR2019]                     [<class 'str'>]          237      0.00            0\n=====================================\nConsole_sales Summary\n\nTotal rows:  84\n\nTotal full null rows:  0\n Column         Data_type  No_miss_Qty  %Missing  Missing_Qty\n   Year   [<class 'int'>]           84       0.0            0\n   Dato   [<class 'str'>]           84       0.0            0\nConsole   [<class 'str'>]           84       0.0            0\nCompany   [<class 'str'>]           84       0.0            0\n  Sales [<class 'float'>]           84       0.0            0\n=====================================\nuser_reviews Summary\n\nTotal rows:  25799\n\nTotal full null rows:  0\n  Column                 Data_type  No_miss_Qty  %Missing  Missing_Qty\n user_id           [<class 'str'>]        25799       0.0            0\nuser_url           [<class 'str'>]        25799       0.0            0\n reviews [<class 'numpy.ndarray'>]        25799       0.0            0\n=====================================\nusers_items Summary\n\nTotal rows:  88310\n\nTotal full null rows:  0\n     Column                 Data_type  No_miss_Qty  %Missing  Missing_Qty\n    user_id           [<class 'str'>]        88310       0.0            0\nitems_count           [<class 'int'>]        88310       0.0            0\n   steam_id           [<class 'str'>]        88310       0.0            0\n   user_url           [<class 'str'>]        88310       0.0            0\n      items [<class 'numpy.ndarray'>]        88310       0.0            0\n=====================================\nsteam_games Summary\n\nTotal rows:  120445\n\nTotal full null rows:  0\n      Column                                     Data_type  No_miss_Qty  %Missing  Missing_Qty\n   publisher           [<class 'NoneType'>, <class 'str'>]        24083     80.00        96362\n      genres [<class 'NoneType'>, <class 'numpy.ndarray'>]        28852     76.05        91593\n    app_name           [<class 'NoneType'>, <class 'str'>]        32133     73.32        88312\n       title           [<class 'NoneType'>, <class 'str'>]        30085     75.02        90360\n         url           [<class 'NoneType'>, <class 'str'>]        32135     73.32        88310\nrelease_date           [<class 'NoneType'>, <class 'str'>]        30068     75.04        90377\n        tags [<class 'NoneType'>, <class 'numpy.ndarray'>]        31972     73.46        88473\n reviews_url           [<class 'NoneType'>, <class 'str'>]        32133     73.32        88312\n       specs [<class 'NoneType'>, <class 'numpy.ndarray'>]        31465     73.88        88980\n       price                               [<class 'str'>]       120445      0.00            0\nearly_access          [<class 'NoneType'>, <class 'bool'>]        32135     73.32        88310\n          id           [<class 'NoneType'>, <class 'str'>]        32133     73.32        88312\n   developer           [<class 'NoneType'>, <class 'str'>]        28836     76.06        91609\n=====================================\nVideo Games Sales Summary\n\nTotal rows:  16719\n\nTotal full null rows:  0\n         Column                           Data_type  No_miss_Qty  %Missing  Missing_Qty\n           Name [<class 'str'>, <class 'NoneType'>]        16717      0.01            2\n       Platform                     [<class 'str'>]        16719      0.00            0\nYear_of_Release                   [<class 'float'>]        16450      1.61          269\n          Genre [<class 'str'>, <class 'NoneType'>]        16717      0.01            2\n      Publisher [<class 'str'>, <class 'NoneType'>]        16665      0.32           54\n       NA_Sales                   [<class 'float'>]        15848      5.21          871\n       EU_Sales                   [<class 'float'>]        15520      7.17         1199\n       JP_Sales                   [<class 'float'>]        16719      0.00            0\n    Other_Sales                   [<class 'float'>]        15341      8.24         1378\n   Global_Sales                   [<class 'float'>]        15728      5.93          991\n   Critic_Score                   [<class 'float'>]         8137     51.33         8582\n   Critic_Count                   [<class 'float'>]         8137     51.33         8582\n     User_Score [<class 'str'>, <class 'NoneType'>]        10015     40.10         6704\n     User_Count                   [<class 'float'>]         7590     54.60         9129\n      Developer [<class 'str'>, <class 'NoneType'>]        10096     39.61         6623\n         Rating [<class 'str'>, <class 'NoneType'>]         9950     40.49         6769\n=====================================\n"]},{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"[              Column                            Data_type  No_miss_Qty  \\\n 0              appid                      [<class 'int'>]        27075   \n 1               name                      [<class 'str'>]        27075   \n 2       release_date                      [<class 'str'>]        27075   \n 3            english                      [<class 'int'>]        27075   \n 4          developer  [<class 'str'>, <class 'NoneType'>]        27074   \n 5          publisher  [<class 'str'>, <class 'NoneType'>]        27061   \n 6          platforms                      [<class 'str'>]        27075   \n 7       required_age                      [<class 'int'>]        27075   \n 8         categories                      [<class 'str'>]        27075   \n 9             genres                      [<class 'str'>]        27075   \n 10     steamspy_tags                      [<class 'str'>]        27075   \n 11      achievements                      [<class 'int'>]        27075   \n 12  positive_ratings                      [<class 'int'>]        27075   \n 13  negative_ratings                      [<class 'int'>]        27075   \n 14  average_playtime                      [<class 'int'>]        27075   \n 15   median_playtime                      [<class 'int'>]        27075   \n 16            owners                      [<class 'str'>]        27075   \n 17             price                    [<class 'float'>]        27075   \n \n     %Missing  Missing_Qty  \n 0       0.00            0  \n 1       0.00            0  \n 2       0.00            0  \n 3       0.00            0  \n 4       0.00            1  \n 5       0.05           14  \n 6       0.00            0  \n 7       0.00            0  \n 8       0.00            0  \n 9       0.00            0  \n 10      0.00            0  \n 11      0.00            0  \n 12      0.00            0  \n 13      0.00            0  \n 14      0.00            0  \n 15      0.00            0  \n 16      0.00            0  \n 17      0.00            0  ,\n            Column                            Data_type  No_miss_Qty  %Missing  \\\n 0     Series Name  [<class 'str'>, <class 'NoneType'>]          234      1.27   \n 1     Series Code  [<class 'str'>, <class 'NoneType'>]          232      2.11   \n 2    Country Name  [<class 'str'>, <class 'NoneType'>]          232      2.11   \n 3    Country Code  [<class 'str'>, <class 'NoneType'>]          232      2.11   \n 4   2000 [YR2000]                      [<class 'str'>]          237      0.00   \n 5   2001 [YR2001]                      [<class 'str'>]          237      0.00   \n 6   2002 [YR2002]                      [<class 'str'>]          237      0.00   \n 7   2003 [YR2003]                      [<class 'str'>]          237      0.00   \n 8   2004 [YR2004]                      [<class 'str'>]          237      0.00   \n 9   2005 [YR2005]                      [<class 'str'>]          237      0.00   \n 10  2006 [YR2006]                      [<class 'str'>]          237      0.00   \n 11  2007 [YR2007]                      [<class 'str'>]          237      0.00   \n 12  2008 [YR2008]                      [<class 'str'>]          237      0.00   \n 13  2009 [YR2009]                      [<class 'str'>]          237      0.00   \n 14  2010 [YR2010]                      [<class 'str'>]          237      0.00   \n 15  2011 [YR2011]                      [<class 'str'>]          237      0.00   \n 16  2012 [YR2012]                      [<class 'str'>]          237      0.00   \n 17  2013 [YR2013]                      [<class 'str'>]          237      0.00   \n 18  2014 [YR2014]                      [<class 'str'>]          237      0.00   \n 19  2015 [YR2015]                      [<class 'str'>]          237      0.00   \n 20  2016 [YR2016]                      [<class 'str'>]          237      0.00   \n 21  2017 [YR2017]                      [<class 'str'>]          237      0.00   \n 22  2018 [YR2018]                      [<class 'str'>]          237      0.00   \n 23  2019 [YR2019]                      [<class 'str'>]          237      0.00   \n \n     Missing_Qty  \n 0             3  \n 1             5  \n 2             5  \n 3             5  \n 4             0  \n 5             0  \n 6             0  \n 7             0  \n 8             0  \n 9             0  \n 10            0  \n 11            0  \n 12            0  \n 13            0  \n 14            0  \n 15            0  \n 16            0  \n 17            0  \n 18            0  \n 19            0  \n 20            0  \n 21            0  \n 22            0  \n 23            0  ,\n     Column          Data_type  No_miss_Qty  %Missing  Missing_Qty\n 0     Year    [<class 'int'>]           84       0.0            0\n 1     Dato    [<class 'str'>]           84       0.0            0\n 2  Console    [<class 'str'>]           84       0.0            0\n 3  Company    [<class 'str'>]           84       0.0            0\n 4    Sales  [<class 'float'>]           84       0.0            0,\n      Column                  Data_type  No_miss_Qty  %Missing  Missing_Qty\n 0   user_id            [<class 'str'>]        25799       0.0            0\n 1  user_url            [<class 'str'>]        25799       0.0            0\n 2   reviews  [<class 'numpy.ndarray'>]        25799       0.0            0,\n         Column                  Data_type  No_miss_Qty  %Missing  Missing_Qty\n 0      user_id            [<class 'str'>]        88310       0.0            0\n 1  items_count            [<class 'int'>]        88310       0.0            0\n 2     steam_id            [<class 'str'>]        88310       0.0            0\n 3     user_url            [<class 'str'>]        88310       0.0            0\n 4        items  [<class 'numpy.ndarray'>]        88310       0.0            0,\n           Column                                      Data_type  No_miss_Qty  \\\n 0      publisher            [<class 'NoneType'>, <class 'str'>]        24083   \n 1         genres  [<class 'NoneType'>, <class 'numpy.ndarray'>]        28852   \n 2       app_name            [<class 'NoneType'>, <class 'str'>]        32133   \n 3          title            [<class 'NoneType'>, <class 'str'>]        30085   \n 4            url            [<class 'NoneType'>, <class 'str'>]        32135   \n 5   release_date            [<class 'NoneType'>, <class 'str'>]        30068   \n 6           tags  [<class 'NoneType'>, <class 'numpy.ndarray'>]        31972   \n 7    reviews_url            [<class 'NoneType'>, <class 'str'>]        32133   \n 8          specs  [<class 'NoneType'>, <class 'numpy.ndarray'>]        31465   \n 9          price                                [<class 'str'>]       120445   \n 10  early_access           [<class 'NoneType'>, <class 'bool'>]        32135   \n 11            id            [<class 'NoneType'>, <class 'str'>]        32133   \n 12     developer            [<class 'NoneType'>, <class 'str'>]        28836   \n \n     %Missing  Missing_Qty  \n 0      80.00        96362  \n 1      76.05        91593  \n 2      73.32        88312  \n 3      75.02        90360  \n 4      73.32        88310  \n 5      75.04        90377  \n 6      73.46        88473  \n 7      73.32        88312  \n 8      73.88        88980  \n 9       0.00            0  \n 10     73.32        88310  \n 11     73.32        88312  \n 12     76.06        91609  ,\n              Column                            Data_type  No_miss_Qty  \\\n 0              Name  [<class 'str'>, <class 'NoneType'>]        16717   \n 1          Platform                      [<class 'str'>]        16719   \n 2   Year_of_Release                    [<class 'float'>]        16450   \n 3             Genre  [<class 'str'>, <class 'NoneType'>]        16717   \n 4         Publisher  [<class 'str'>, <class 'NoneType'>]        16665   \n 5          NA_Sales                    [<class 'float'>]        15848   \n 6          EU_Sales                    [<class 'float'>]        15520   \n 7          JP_Sales                    [<class 'float'>]        16719   \n 8       Other_Sales                    [<class 'float'>]        15341   \n 9      Global_Sales                    [<class 'float'>]        15728   \n 10     Critic_Score                    [<class 'float'>]         8137   \n 11     Critic_Count                    [<class 'float'>]         8137   \n 12       User_Score  [<class 'str'>, <class 'NoneType'>]        10015   \n 13       User_Count                    [<class 'float'>]         7590   \n 14        Developer  [<class 'str'>, <class 'NoneType'>]        10096   \n 15           Rating  [<class 'str'>, <class 'NoneType'>]         9950   \n \n     %Missing  Missing_Qty  \n 0       0.01            2  \n 1       0.00            0  \n 2       1.61          269  \n 3       0.01            2  \n 4       0.32           54  \n 5       5.21          871  \n 6       7.17         1199  \n 7       0.00            0  \n 8       8.24         1378  \n 9       5.93          991  \n 10     51.33         8582  \n 11     51.33         8582  \n 12     40.10         6704  \n 13     54.60         9129  \n 14     39.61         6623  \n 15     40.49         6769  ]"},"metadata":{}}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3221673c-cbba-4b70-9f6d-f4850ccdf13a"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"es"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"a1b6b3d0-9bef-4e2a-a731-81e4d801d7a1","default_lakehouse_name":"Bronze","default_lakehouse_workspace_id":"8c7d2edc-a6a8-4f1a-bef1-c8b14449cfd3"}}},"nbformat":4,"nbformat_minor":5}